{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is used to make tables and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rc('hatch', color='w', linewidth=1.5)\n",
    "font = {'family' : 'Arial',\n",
    "        'size'   : 6.5}\n",
    "plt.rc('font', **font)\n",
    "mpl.rc('axes', titlesize=7, labelsize=6.5)\n",
    "mpl.rc('xtick', labelsize=6.5)\n",
    "mpl.rc('ytick', labelsize=6.5)\n",
    "mpl.rc('legend', fontsize=6.5)\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['xtick.major.width'] = 0.5\n",
    "plt.rcParams['ytick.major.width'] = 0.5\n",
    "from visual_utils.utils_tabfig import *\n",
    "sys.path.append('../')\n",
    "from src_safety_evaluation.validation_utils.utils_eval_metrics import *\n",
    "from src_safety_evaluation.validation_utils.utils_evaluation import optimize_threshold\n",
    "\n",
    "single_column_width = 3.46\n",
    "double_column_width = 7.05\n",
    "\n",
    "path_processed = '../ProcessedData/'\n",
    "path_prepared = '../PreparedData/'\n",
    "path_result = '../ResultData/'\n",
    "path_raw = '../RawData/'\n",
    "path_fig = 'Figures/'\n",
    "if not os.path.exists(path_fig):\n",
    "    os.makedirs(path_fig)\n",
    "\n",
    "def savefig(fig, name, path_fig=path_fig):\n",
    "    fig.savefig(f'{path_fig}{name}.pdf', dpi=600, bbox_inches='tight', pad_inches=0.05)\n",
    "\n",
    "def number_subfig(ax, label, x, y):\n",
    "    ax.text(x, y, label, fontsize=8, fontweight='bold', va='top', ha='left', transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1 Accident Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(double_column_width*1.2,3),gridspec_kw={'hspace':0.5,'wspace':0.2,'width_ratios':[1.,1.1]})\n",
    "ax_total = axes[0].inset_axes([0., 0.72, 0.95, 0.365])\n",
    "global_deaths_over_years(ax_total, path_raw)\n",
    "ax_total.set_title('Global deaths in road crashes over years')\n",
    "ax_unece = axes[0].inset_axes([0., 0., 0.95, 0.45])\n",
    "unece_accident_reduction(ax_unece, path_raw)\n",
    "ax_unece.set_title('Accidents by location in UNECE countries', y=1.05)\n",
    "\n",
    "ax_nl = axes[1].inset_axes([0., 0.56, 0.75, 0.54], xlim=(0, 1), ylim=(-0.5, 0.5))\n",
    "location_type_nl(ax_nl, path_raw)\n",
    "ax_nl.set_title('Road crash types 2021-2023 (NL)', y=0.97)\n",
    "ax_us = axes[1].inset_axes([0., -0.08, 0.75, 0.54], xlim=(0, 1), ylim=(-0.5, 0.5))\n",
    "location_type_us(ax_us, path_raw)\n",
    "ax_us.set_title('Road crash types 2021-2023 (US)', y=0.97)\n",
    "\n",
    "remove_box(axes[0])\n",
    "remove_box(axes[1])\n",
    "\n",
    "number_subfig(ax_total, 'a', -0.1, 1.25)\n",
    "number_subfig(ax_unece, 'b', -0.1, 1.21)\n",
    "number_subfig(axes[1], 'c', -0.03, 1.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(fig, 'Fig1_AccidentStatistics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2 Effectiveness, Scability, Context-awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(double_column_width*1.23, 5.8))\n",
    "gs = fig.add_gridspec(42, 28, hspace=1.3, wspace=1.5)\n",
    "\n",
    "# Effectiveness plots\n",
    "models = ['highD_current', 'ACT', 'TTC2D', 'TAdv', 'EI']\n",
    "model_labels = ['GSSM', 'ACT', 'TTC2D', 'TAdv', 'EI']\n",
    "colors = cmap([0.15, 0.3, 0.45, 0.6, 0.75])\n",
    "\n",
    "warning_files = os.listdir(path_result + 'Conflicts/Results/')\n",
    "warning_files = [f for f in warning_files if f.startswith('RiskEval_') and f.endswith('.h5')]\n",
    "conflict_warning = pd.concat([pd.read_hdf(path_result+'Conflicts/Results/'+f, key='results') for f in tqdm(warning_files, desc='Reading files')])\n",
    "voted_events = pd.read_csv(path_result + 'Conflicts/Voted_conflicting_targets.csv').set_index('event_id')\n",
    "voted_events = voted_events[voted_events['target_id']>=0]\n",
    "voted_events['event'] = [category[c] for c in voted_events['event_category'].values]\n",
    "\n",
    "axroc, axprc, axatc = fig.add_subplot(gs[2:12,:6]), fig.add_subplot(gs[2:12,6:12]), fig.add_subplot(gs[2:12,12:18])\n",
    "axroc, axprc, axatc = draw_effectiveness(axroc, axprc, axatc, models, colors, conflict_warning)\n",
    "handles, legends = axroc.get_legend_handles_labels()\n",
    "fig.legend(handles, ['Safety-critical']+model_labels, loc='lower center', bbox_to_anchor=(0.36, 0.875),\n",
    "           ncol=len(models)+1, frameon=False, handlelength=2.5, handletextpad=0.4, columnspacing=1)\n",
    "\n",
    "# Data scalability\n",
    "warning_files = os.listdir(path_result + 'Analyses/')\n",
    "warning_files = [f for f in warning_files if f.startswith('Warning_') and f.endswith('.h5')]\n",
    "warning_files = [f for f in warning_files if 'mixed' in f or 'SafeBaseline' in f]\n",
    "conflict_warning = pd.concat([pd.read_hdf(path_result+'Analyses/'+f, key='results') for f in tqdm(warning_files, desc='Reading files')])\n",
    "event_meta = pd.read_csv(path_result + 'Analyses/EventMeta.csv')\n",
    "ds_axes = [fig.add_subplot(gs[:12,19:28]), fig.add_subplot(gs[16:27,19:28]), fig.add_subplot(gs[17:27,:18])]\n",
    "ds_axes = draw_data_scalability(conflict_warning, event_meta, axes=ds_axes)\n",
    "ds_axes[0].set_title('Increasing crossings in ArgoverseHV', pad=5)\n",
    "labels = ['$A_{80\\\\%}^\\\\mathrm{ROC}$', '$A_{90\\\\%}^\\\\mathrm{ROC}$', '$\\\\mathrm{Precision}_{80\\\\%}^\\\\mathrm{PRC}$', \n",
    "          '$\\\\mathrm{Precision}_{90\\\\%}^\\\\mathrm{PRC}$', '$\\\\mathrm{AUPRC}$']\n",
    "handles, _ = ds_axes[0].get_legend_handles_labels()\n",
    "ds_axes[0].legend(handles, labels, loc='center right', bbox_to_anchor=(1.04, 0.48), ncol=3, fontsize=6,\n",
    "                  frameon=False, handlelength=2.5, handletextpad=0.4, columnspacing=1, labelspacing=0.)\n",
    "ds_axes[1].set_title('Increasing lane changes in highD', pad=2)\n",
    "ds_axes[1].set_ylabel('Metric value', labelpad=1)\n",
    "handles, _ = ds_axes[1].get_legend_handles_labels()\n",
    "ds_axes[1].legend(handles, labels, loc='lower right', bbox_to_anchor=(1.04, -0.05), ncol=3, fontsize=6,\n",
    "                  frameon=False, handlelength=2.5, handletextpad=0.4, columnspacing=1, labelspacing=0.)\n",
    "ds_axes[2].set_title('Evaluation on lateral interactions', pad=5)\n",
    "\n",
    "# Feature scalability\n",
    "warning_files = os.listdir(path_result + 'Conflicts/Results/')\n",
    "warning_files = [f for f in warning_files if f.startswith('RiskEval_') and f.endswith('.h5')]\n",
    "conflict_warning = pd.concat([pd.read_hdf(path_result+'Conflicts/Results/'+f, key='results') for f in tqdm(warning_files, desc='Reading files')])\n",
    "fs_axes = [fig.add_subplot(gs[32:42,4*i:4*(i+1)]) for i in range(7)]\n",
    "fs_axes = draw_feature_scalability(conflict_warning, axes=fs_axes)\n",
    "for ax in fs_axes[1:]:\n",
    "    ax.tick_params(axis='y', which='major', pad=2) # type: ignore\n",
    "handles, labels = fs_axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles[0].patches+handles[1].patches,\n",
    "           ['S-C', 'S-CE', 'S-CET', 'S-Ca', 'S-CaE', 'S-CaET'],\n",
    "           loc='lower center', bbox_to_anchor=(0.5, 0.065),\n",
    "           ncol=6, frameon=False, handlelength=1.8, handletextpad=0.5, columnspacing=1.5)\n",
    "\n",
    "number_subfig(axroc, 'a', -0.32, 1.38)\n",
    "number_subfig(ds_axes[0], 'b', -0.1, 1.12)\n",
    "number_subfig(ds_axes[1], 'c', -0.1, 1.1)\n",
    "number_subfig(ds_axes[2], 'd', -0.04, 1.2)\n",
    "number_subfig(fs_axes[0], 'e', -0.2, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(fig, 'Result123')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2 Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_table = pd.DataFrame(columns=['model','auprc','aroc_80','aroc_90','pprc_80','pprc_90','PTTI_star','mTTI_star'])\n",
    "for model, model_label in zip(models, model_labels):\n",
    "    metrics = get_eval_metrics(conflict_warning[conflict_warning['model']==model],\n",
    "                               thresholds={'roc': [0.80, 0.90], 'prc':[0.80, 0.90],'tti':1.5}, with_CI=True)\n",
    "    metrics['model'] = model_label\n",
    "    metric_table.loc[len(metric_table), list(metrics.keys())] = list(metrics.values())\n",
    "metric_table[metric_table.columns[1:]] = metric_table[metric_table.columns[1:]].astype(float)\n",
    "mtti_star = ['mTTI_star', 'TTI_star_q25', 'TTI_star_q75', 'TTI_star_lowCI', 'TTI_star_upCI']\n",
    "metric_table['mTTI_star'] = metric_table['mTTI_star'].round(2)\n",
    "metric_table = highlight(metric_table, max_cols=metric_table.columns[1:-4], involve_second=True)\n",
    "metric_table['mTTI_star'] = (metric_table['mTTI_star'] + ' [' + \n",
    "                             metric_table['TTI_star_q25'].apply(lambda x: f\"{x:.2f}\") + '--' + \n",
    "                             metric_table['TTI_star_q75'].apply(lambda x: f\"{x:.2f}\") + ']; ' +\n",
    "                             metric_table['TTI_star_lowCI'].apply(lambda x: f\"{x:.2f}\") + '--' +\n",
    "                             metric_table['TTI_star_upCI'].apply(lambda x: f\"{x:.2f}\"))\n",
    "metric_table['mTTI_star'] = [metric_table['mTTI_star'].iloc[i].replace('0 [',' [').replace('0}','}') for i in range(len(metric_table))]\n",
    "metric_table = metric_table.drop(columns=mtti_star[1:])\n",
    "metric_table = metric_table.rename(columns={'model':'Method', 'auprc':'AUPRC',\n",
    "                             'aroc_80':'$A_{80\\\\%}^\\\\mathrm{ROC}$', 'aroc_90':'$A_{90\\\\%}^\\\\mathrm{ROC}$',\n",
    "                             'pprc_80':'$\\\\mathrm{Precision}_{80\\\\%}^\\\\mathrm{PRC}$', 'pprc_90':'$\\\\mathrm{Precision}_{90\\\\%}^\\\\mathrm{PRC}$',\n",
    "                             'PTTI_star':'$P^*_{\\\\mathrm{TTI}\\\\geq1.5}$','mTTI_star':'$m\\\\mathrm{TTI}^*$ [$Q1$--$Q3$]; $99\\\\%CI$'})\n",
    "metric_table = metric_table.set_index('Method').loc[model_labels]\n",
    "metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric_table.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 3 One GSSM for all interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_meta = event_meta[event_meta['conflict']!='none']\n",
    "models = ['SafeBaseline_current_environment_profiles', 'ACT', 'TTC2D', 'TAdv', 'EI']\n",
    "model_labels = ['GSSM', 'ACT', 'TTC2D', 'TAdv', 'EI']\n",
    "\n",
    "event_metric_list = []\n",
    "event_metric_list.append([['leading'], 'Rear-end'])\n",
    "event_metric_list.append([['adjacent_lane'], 'Adjacent lane'])\n",
    "event_metric_list.append([['turning_into_parallel','turning_across_opposite','turning_into_parallel','turning_into_opposite','intersection_crossing'], \n",
    "                         'Crossing/turning'])\n",
    "event_metric_list.append([['merging'], 'Merging'])\n",
    "event_metric_list.append([['pedestrian','cyclist','animal'], 'With pedestrian/cyclist/animal'])\n",
    "\n",
    "metric_table = []\n",
    "for events, event_label in tqdm(event_metric_list):\n",
    "    event_metrics = pd.DataFrame(columns=['Event', 'model','auprc','aroc_80','aroc_90','pprc_80','pprc_90','PTTI_star','mTTI_star'])\n",
    "    for model, model_label in zip(models, model_labels):\n",
    "        event_ids = event_meta[event_meta['conflict'].isin(events)]['event_id'].values\n",
    "        filtered_warning = conflict_warning[(conflict_warning['event_id'].isin(event_ids))]\n",
    "        filtered_warning = filtered_warning[filtered_warning['model']==model]\n",
    "\n",
    "        metrics = get_eval_metrics(filtered_warning, thresholds={'roc': [0.80, 0.90], 'prc':[0.80, 0.90],'tti':1.5}, with_CI=True)\n",
    "        metrics['Event'] = event_label\n",
    "        metrics['model'] = model_label\n",
    "        event_metrics.loc[len(event_metrics), list(metrics.keys())] = list(metrics.values())\n",
    "    event_metrics[event_metrics.columns[2:]] = event_metrics[event_metrics.columns[2:]].astype(float)\n",
    "    mtti_star = ['mTTI_star', 'TTI_star_q25', 'TTI_star_q75', 'TTI_star_lowCI', 'TTI_star_upCI']\n",
    "    event_metrics['mTTI_star'] = event_metrics['mTTI_star'].round(2)\n",
    "    event_metrics = highlight(event_metrics, max_cols=event_metrics.columns[2:-4], involve_second=True)\n",
    "    event_metrics['mTTI_star'] = (event_metrics['mTTI_star'] + ' [' + \n",
    "                                event_metrics['TTI_star_q25'].apply(lambda x: f\"{x:.2f}\") + '--' + \n",
    "                                event_metrics['TTI_star_q75'].apply(lambda x: f\"{x:.2f}\") + ']; ' +\n",
    "                                event_metrics['TTI_star_lowCI'].apply(lambda x: f\"{x:.2f}\") + '--' +\n",
    "                                event_metrics['TTI_star_upCI'].apply(lambda x: f\"{x:.2f}\"))\n",
    "    event_metrics['mTTI_star'] = [event_metrics['mTTI_star'].iloc[i].replace('0 [',' [').replace('0}','}') for i in range(len(event_metrics))]\n",
    "    event_metrics = event_metrics.drop(columns=mtti_star[1:])\n",
    "    event_metrics['Number of events'] = f\"{filtered_warning['event_id'].nunique()}\"\n",
    "    metric_table.append(event_metrics)\n",
    "metric_table = pd.concat(metric_table, axis=0)\n",
    "metric_table = metric_table.rename(columns={'model':'Method', 'aroc_80':'$A_{80\\\\%}^\\\\mathrm{ROC}$', 'aroc_90':'$A_{90\\\\%}^\\\\mathrm{ROC}$',\n",
    "                                            'pprc_80':'$\\\\mathrm{Precision}_{80\\\\%}^\\\\mathrm{PRC}$', 'pprc_90':'$\\\\mathrm{Precision}_{90\\\\%}^\\\\mathrm{PRC}$',\n",
    "                                            'auprc':'$\\\\mathrm{AUPRC}$', 'PTTI_star':'$P^*_{\\\\mathrm{TTI}\\\\geq1.5}$', 'mTTI_star':'$m\\\\mathrm{TTI}^*$ [$Q1$--$Q3$]; $99\\\\%CI$'})\n",
    "\n",
    "metric_table = metric_table.set_index(['Event','Number of events','Method'])\n",
    "metric_table.replace('nan', 'N/A', inplace=True)\n",
    "metric_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric_table.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_list = [['leading'], ['merging']]\n",
    "model = models[0]\n",
    "\n",
    "for events in events_list:\n",
    "    print(events)\n",
    "    event_ids = event_meta[event_meta['conflict'].isin(events)]['event_id'].values\n",
    "    filtered_warning = conflict_warning[(conflict_warning['event_id'].isin(event_ids))]\n",
    "    filtered_warning = filtered_warning[filtered_warning['model']==model]\n",
    "    _, _, optimal_threshold = optimize_threshold(filtered_warning, 'GSSM', return_stats=True)\n",
    "    print(f\"FP:{optimal_threshold['FP']}/({optimal_threshold['TP']+optimal_threshold['FP']}) FN:{optimal_threshold['FN']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3 Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution = pd.read_hdf(path_result + 'FeatureAttribution/SafeBaseline_current_environment_profiles.h5').reset_index()\n",
    "eg_columns = [var for var in attribution.columns[4:25]]\n",
    "columns = [var[3:] for var in attribution.columns[4:25]]\n",
    "attribution['eg_sum'] = attribution[eg_columns].sum(axis=1)\n",
    "positive_mask = (attribution[eg_columns]>0)\n",
    "attribution['positive_sum'] = (attribution[eg_columns]*positive_mask.astype(int)).sum(axis=1)\n",
    "negative_mask = (attribution[eg_columns]<0)\n",
    "attribution['negative_sum'] = (attribution[eg_columns]*negative_mask.astype(int)).sum(axis=1)\n",
    "\n",
    "conflict_warning = pd.read_hdf(path_result + 'Conflicts/Results/RiskEval_SafeBaseline_current_environment_profiles.h5', key='results')\n",
    "_, _, optimal_threshold = optimize_threshold(conflict_warning, 'GSSM', return_stats=True)\n",
    "conflict_warning = conflict_warning[conflict_warning['threshold']==optimal_threshold['threshold']].set_index('event_id')\n",
    "_, _, meta_events, environment = read_meta(path_processed, path_result)\n",
    "event_ids = conflict_warning.index.values\n",
    "meta_events = meta_events.loc[event_ids]\n",
    "environment = environment.loc[event_ids]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(double_column_width, 2.8), constrained_layout=True, gridspec_kw={'wspace':0.07})\n",
    "ax_conflit = axes[0]\n",
    "ax_conflit.set_title('Top factors in leading to and avoiding lateral conflicts', pad=15)\n",
    "remove_box(ax_conflit)\n",
    "ax_adj_danger = ax_conflit.inset_axes([0, 0.55, 0.46, 0.45])\n",
    "ax_adj_danger.set_title('Danger in adjacent lane', pad=3)\n",
    "filtered_warning = conflict_warning.loc[meta_events[(meta_events['conflict']=='Adjacent lane')].index.values]\n",
    "warning_statistics, non_warning_statistics = get_rank(filtered_warning, attribution, eg_columns, optimal_threshold, type='both')\n",
    "plot_bars(warning_statistics, ax_adj_danger)\n",
    "\n",
    "ax_adj_safe = ax_conflit.inset_axes([0.54, 0.55, 0.46, 0.45])\n",
    "ax_adj_safe.set_title('Safe in adjacent lane', pad=3)\n",
    "plot_bars(non_warning_statistics, ax_adj_safe)\n",
    "\n",
    "ax_cat_danger = ax_conflit.inset_axes([0, -0.05, 0.46, 0.45])\n",
    "ax_cat_danger.set_title('Danger during crossing/turning', pad=3)\n",
    "filtered_warning = conflict_warning.loc[meta_events[(meta_events['conflict']=='Crossing/turning')].index.values]\n",
    "warning_statistics, non_warning_statistics = get_rank(filtered_warning, attribution, eg_columns, optimal_threshold, type='both')\n",
    "plot_bars(warning_statistics, ax_cat_danger)\n",
    "\n",
    "ax_cat_safe = ax_conflit.inset_axes([0.54, -0.05, 0.46, 0.45])\n",
    "ax_cat_safe.set_title('Safe during crossing/turning', pad=3)\n",
    "plot_bars(non_warning_statistics, ax_cat_safe)\n",
    "\n",
    "ax_environment = axes[1]\n",
    "ax_environment.set_title('Top factors in conflicts in adverse environments', pad=15)\n",
    "remove_box(ax_environment)\n",
    "ax_wea = ax_environment.inset_axes([0, 0.55, 0.46, 0.45])\n",
    "ax_wea.set_title('Raining weather', pad=3)\n",
    "filtered_warning = conflict_warning.loc[environment[(environment['weather']=='Raining')|\n",
    "                                                    (environment['weather']=='Mist/Light Rain')].index.values]\n",
    "warning_statistics, _ = get_rank(filtered_warning, attribution, eg_columns, optimal_threshold, type='warning')\n",
    "plot_bars(warning_statistics, ax_wea)\n",
    "\n",
    "ax_road = ax_environment.inset_axes([0.54, 0.55, 0.46, 0.45])\n",
    "ax_road.set_title('Not dry road', pad=3)\n",
    "filtered_warning = conflict_warning.loc[environment[(environment['surfaceCondition']!='Dry')].index.values]\n",
    "warning_statistics, _ = get_rank(filtered_warning, attribution, eg_columns, optimal_threshold, type='warning')\n",
    "plot_bars(warning_statistics, ax_road)\n",
    "\n",
    "ax_light = ax_environment.inset_axes([0, -0.05, 0.46, 0.45])\n",
    "ax_light.set_title('Not in daylight', pad=3)\n",
    "filtered_warning = conflict_warning.loc[environment[(environment['lighting']!='Daylight')].index.values]\n",
    "warning_statistics, _ = get_rank(filtered_warning, attribution, eg_columns, optimal_threshold, type='warning')\n",
    "plot_bars(warning_statistics, ax_light)\n",
    "\n",
    "ax_traffic = ax_environment.inset_axes([0.54, -0.05, 0.46, 0.45])\n",
    "ax_traffic.set_title('Unstable traffic flow', pad=3)\n",
    "filtered_warning = conflict_warning.loc[environment[(environment['trafficDensity']=='Level-of-service D: Unstable flow - temporary restrictions substantially slow driver')].index.values]\n",
    "warning_statistics, _ = get_rank(filtered_warning, attribution, eg_columns, optimal_threshold, type='warning')\n",
    "plot_bars(warning_statistics, ax_traffic)\n",
    "\n",
    "for ax in [ax_cat_danger, ax_cat_safe, ax_light, ax_traffic]:\n",
    "    ax.set_xlabel('Frequency of being top 3 factors')\n",
    "\n",
    "number_subfig(ax_conflit, 'a', -0.005, 1.15)\n",
    "number_subfig(ax_environment, 'b', -0.005, 1.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(fig, 'Result5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Data Figure 2 SHRP2 statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = draw_SHRP2(path_processed, path_result, figsize=(double_column_width, 3.8))\n",
    "axes[0].set_title('Event counts', y=1.05)\n",
    "axes[1].set_title('Event types', y=1.05)\n",
    "axes[2].set_title('Weather and road surface conditions', y=1.0)\n",
    "axes[3].set_title('Lighting conditions', y=1.0)\n",
    "axes[4].set_title('Traffic conditions', y=1.0)\n",
    "number_subfig(axes[0], 'a', -0.03, 1.15)\n",
    "number_subfig(axes[1], 'b', -0.1, 1.15)\n",
    "number_subfig(axes[2], 'c', -0.36, 1.14)\n",
    "number_subfig(axes[3], 'd', -0.05, 1.14)\n",
    "number_subfig(axes[4], 'e', -0.1, 1.14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(fig, 'SHRP2_event_counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Data Figure 3 Danger and safe period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = draw_periods(figsize=(double_column_width, 1.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(fig, 'Safe_danger_period')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Data Figure 4 One GSSM for all interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warning_files = os.listdir(path_result + 'Conflicts/Results/')\n",
    "warning_files = [f for f in warning_files if f.startswith('RiskEval_') and f.endswith('.h5')]\n",
    "conflict_warning = pd.concat([pd.read_hdf(path_result+'Conflicts/Results/'+f, key='results') for f in tqdm(warning_files, desc='Reading files')])\n",
    "event_meta = pd.read_csv(path_result + 'Analyses/EventMeta.csv')\n",
    "voted_events = pd.read_csv(path_result + 'Conflicts/Voted_conflicting_targets.csv').set_index('event_id')\n",
    "voted_events = voted_events[voted_events['target_id']>=0]\n",
    "voted_events['event'] = [category[c] for c in voted_events['event_category'].values]\n",
    "\n",
    "models = ['SafeBaseline_current_environment_profiles', \n",
    "          'ACT', \n",
    "          'TTC2D']\n",
    "\n",
    "fig, axes = draw_generalisability(conflict_warning, models, event_meta, voted_events, figsize=(double_column_width*0.94, 2.8))\n",
    "axes[0].set_title('Event type distribution', pad=0)\n",
    "axes[1].set_title('Receiver operating characteristic (ROC) curves', pad=11.5)\n",
    "axes[2].set_title('Precision-recall (PRC) curves', pad=5)\n",
    "axes[3].set_title('Accuracy-timeliness (ATC() curves', pad=5)\n",
    "number_subfig(axes[0], 'a', -0.05, 1.04)\n",
    "number_subfig(axes[1], 'b', -0.04, 1.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(fig, 'Result4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Figure 1 SHRP2 Reconstruction error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_both = pd.read_csv(path_processed + 'SHRP2/metadata_birdseye.csv').set_index('event_id')\n",
    "meta_both['event'] = [category[c] for c in meta_both['event_category'].values]\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(double_column_width, 1.5), constrained_layout=True)\n",
    "\n",
    "var_list = {'Subject speed': ['m/s', 'v_ekf','speed_comp', np.linspace(-0.008, 0.408, 30)],\n",
    "            'Subject yaw rate': ['rad/s', 'omega_ekf','yaw_rate', np.linspace(-0.00004, 0.00204, 30)],\n",
    "            'Subject acceleration': ['m/s$^2$', 'acc_ekf','acc_lon', np.linspace(-0.02, 1.02, 30)],\n",
    "            'Object displacement': ['m', np.linspace(-0.04, 2.04, 30)],\n",
    "            'Object speed': ['m/s', 'v_ekf','speed_comp', np.linspace(-0.02, 1.02, 30)]}\n",
    "for event_type, color, text_pos in zip(['Crashes', 'Near-crashes', 'Safe baselines'], [cmap(0.4), cmap(0.65), cmap(0.15)], [0.95, 0.65, 0.35]):\n",
    "    if event_type == 'Safe baselines':\n",
    "        data_ego = pd.concat([pd.read_hdf(path_processed + f'SHRP2/SafeBaseline/Ego_birdseye_{i}.h5', key='data') for i in range(1, 5)])\n",
    "        data_sur = pd.concat([pd.read_hdf(path_processed + f'SHRP2/SafeBaseline/Surrounding_birdseye_{i}.h5', key='data') for i in range(1, 5)])\n",
    "    else:\n",
    "        event_categories = meta_both[meta_both['event']==event_type]['event_category'].unique()\n",
    "        data_ego = []\n",
    "        data_sur = []\n",
    "        for event_cat in event_categories:\n",
    "            data_ego.append(pd.read_hdf(path_processed + f'SHRP2/{event_cat}/Ego_birdseye.h5', key='data'))\n",
    "            data_sur.append(pd.read_hdf(path_processed + f'SHRP2/{event_cat}/Surrounding_birdseye.h5', key='data'))\n",
    "        data_ego = pd.concat(data_ego)\n",
    "        data_sur = pd.concat(data_sur)\n",
    "    \n",
    "    data_list = [data_ego, data_ego, data_ego, data_sur, data_sur]\n",
    "    for col, data, key, values in zip(range(5), data_list, var_list.keys(), var_list.values()):\n",
    "        if key == 'Object displacement':\n",
    "            # Mean displacement error\n",
    "            error = ((data['x_ekf']-data['x'])**2 + (data['y_ekf']-data['y'])**2)**0.5\n",
    "            error = error.to_frame(name='error')\n",
    "            error['event_id'] = data['event_id']\n",
    "            error = error.groupby('event_id')['error'].mean()\n",
    "        else:\n",
    "            # Root mean square error\n",
    "            error = (data[values[1]]-data[values[2]])**2\n",
    "            error = error.to_frame(name='squared error')\n",
    "            error['event_id'] = data['event_id']\n",
    "            error = error.groupby('event_id')['squared error'].mean()**0.5\n",
    "            \n",
    "        mean, std = error.mean(), error.std()\n",
    "        axes[col].hist(error, bins=values[-1], density=True, color=color, alpha=0.6, lw=0, label=event_type)\n",
    "        if key == 'Subject yaw rate':\n",
    "            axes[col].text(0.6, text_pos, f'$\\\\mu={mean:.5f}$\\n$\\\\sigma={std:.5f}$', ha='left', va='top', transform=axes[col].transAxes, color=color)\n",
    "        else:\n",
    "            axes[col].text(0.7, text_pos, f'$\\\\mu={mean:.2f}$\\n$\\\\sigma={std:.2f}$', ha='left', va='top', transform=axes[col].transAxes, color=color)\n",
    "        axes[col].set_title(f'{key}', pad=5)\n",
    "        if key == 'Object displacement':\n",
    "            axes[col].set_xlabel(f\"{key.split(' ')[1].capitalize()} MAE ({values[0]})\", labelpad=1)\n",
    "        else:\n",
    "            axes[col].set_xlabel(f\"{key.split(' ')[1].capitalize()} RMSE ({values[0]})\", labelpad=1)\n",
    "        axes[col].set_yticks([])\n",
    "axes[0].set_ylabel('Probability density')\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles[:3], labels[:3], loc='lower center', bbox_to_anchor=(0.5, -0.09),\n",
    "           ncol=3, frameon=False, handlelength=1, handletextpad=0.5, columnspacing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(fig, 'SHRP2_error_distributions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GSSM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
